{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "5415ffc3",
            "metadata": {},
            "source": [
                "# 06 â€“ Advanced Model with Feature Engineering & Ensembling"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b98c7184",
            "metadata": {},
            "source": [
                "This notebook pushes the performance further by:\n",
                "1.  **Feature Engineering**: Creating interaction terms like `loan_to_income` and `monthly_debt`.\n",
                "2.  **Advanced Models**: Using XGBoost, LightGBM, and CatBoost.\n",
                "3.  **Ensembling**: Combining predictions using a Voting Classifier."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "af2b5a8f",
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "sys.path.append(os.path.abspath(\"..\"))\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from pathlib import Path\n",
                "\n",
                "from sklearn.compose import ColumnTransformer\n",
                "from sklearn.impute import SimpleImputer\n",
                "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder, FunctionTransformer\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
                "from sklearn.ensemble import VotingClassifier\n",
                "\n",
                "from xgboost import XGBClassifier\n",
                "from lightgbm import LGBMClassifier\n",
                "from catboost import CatBoostClassifier\n",
                "\n",
                "DATA_DIR = Path('../data')\n",
                "train_path = DATA_DIR / 'train.csv'\n",
                "test_path = DATA_DIR / 'test.csv'\n",
                "\n",
                "train_df = pd.read_csv(train_path)\n",
                "test_df = pd.read_csv(test_path)\n",
                "\n",
                "print(f\"Train shape: {train_df.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "329483b5",
            "metadata": {},
            "source": [
                "## Feature Engineering\n",
                "\n",
                "We create new features that might help the model understand the borrower's financial situation better."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fa876b89",
            "metadata": {},
            "outputs": [],
            "source": [
                "def feature_engineering(df):\n",
                "    df = df.copy()\n",
                "    # Loan to Income Ratio: How big is the loan relative to income?\n",
                "    # Note: This is distinct from 'debt_to_income_ratio' which typically includes ALL debt obligations.\n",
                "    # Correlation between these two is near zero, so this adds new information.\n",
                "    df['loan_to_income'] = df['loan_amount'] / (df['annual_income'] + 1)\n",
                "    \n",
                "    # Monthly Debt: Estimated monthly debt payment\n",
                "    df['monthly_debt'] = (df['annual_income'] / 12) * df['debt_to_income_ratio']\n",
                "    \n",
                "    # Interest Burden: Total interest to be paid (approx)\n",
                "    df['interest_burden'] = df['loan_amount'] * (df['interest_rate'] / 100)\n",
                "    \n",
                "    # Credit Score Binning (Optional, but trees find splits easily so maybe redundant, but let's try)\n",
                "    # df['credit_score_bin'] = pd.cut(df['credit_score'], bins=[0, 580, 670, 740, 800, 850], labels=['Poor', 'Fair', 'Good', 'Very Good', 'Excellent'])\n",
                "    \n",
                "    return df\n",
                "\n",
                "X_train_full = feature_engineering(train_df)\n",
                "X_test_full = feature_engineering(test_df)\n",
                "\n",
                "target_col = 'loan_paid_back'\n",
                "X = X_train_full.drop(columns=[target_col])\n",
                "y = X_train_full[target_col]\n",
                "X_test = X_test_full"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "00bb62e6",
            "metadata": {},
            "source": [
                "## Preprocessing Pipeline\n",
                "\n",
                "We update the pipeline to include the new columns."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b4d0c4fd",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define column groups\n",
                "log_features = ['annual_income']\n",
                "numeric_features = ['debt_to_income_ratio', 'credit_score', 'loan_amount', 'interest_rate',\n",
                "                    'loan_to_income', 'monthly_debt', 'interest_burden']\n",
                "ordinal_features = ['grade_subgrade']\n",
                "categorical_features = ['loan_purpose', 'gender', 'marital_status', 'education_level', 'employment_status']\n",
                "\n",
                "# Transformers\n",
                "log_transformer = Pipeline(steps=[\n",
                "    ('imputer', SimpleImputer(strategy='median')),\n",
                "    ('log', FunctionTransformer(np.log1p, validate=False)),\n",
                "    ('scaler', StandardScaler())\n",
                "])\n",
                "\n",
                "numeric_transformer = Pipeline(steps=[\n",
                "    ('imputer', SimpleImputer(strategy='median')),\n",
                "    ('scaler', StandardScaler())\n",
                "])\n",
                "\n",
                "grades = sorted(X['grade_subgrade'].unique())\n",
                "ordinal_transformer = Pipeline(steps=[\n",
                "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
                "    ('ordinal', OrdinalEncoder(categories=[grades], handle_unknown='use_encoded_value', unknown_value=-1))\n",
                "])\n",
                "\n",
                "categorical_transformer = Pipeline(steps=[\n",
                "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
                "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
                "])\n",
                "\n",
                "preprocessor = ColumnTransformer(\n",
                "    transformers=[\n",
                "        ('log', log_transformer, log_features),\n",
                "        ('num', numeric_transformer, numeric_features),\n",
                "        ('ord', ordinal_transformer, ordinal_features),\n",
                "        ('cat', categorical_transformer, categorical_features)\n",
                "    ]\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "58b13bfa",
            "metadata": {},
            "source": [
                "## Model Training & Ensembling\n",
                "\n",
                "We define the advanced models and a voting classifier."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "dd28d9b9",
            "metadata": {},
            "outputs": [],
            "source": [
                "xgb_clf = XGBClassifier(\n",
                "    n_estimators=500,\n",
                "    learning_rate=0.05,\n",
                "    max_depth=6,\n",
                "    subsample=0.8,\n",
                "    colsample_bytree=0.8,\n",
                "    random_state=42,\n",
                "    n_jobs=-1,\n",
                "    eval_metric='auc'\n",
                ")\n",
                "\n",
                "lgbm_clf = LGBMClassifier(\n",
                "    n_estimators=500,\n",
                "    learning_rate=0.05,\n",
                "    num_leaves=31,\n",
                "    random_state=42,\n",
                "    n_jobs=-1,\n",
                "    verbose=-1\n",
                ")\n",
                "\n",
                "cat_clf = CatBoostClassifier(\n",
                "    iterations=500,\n",
                "    learning_rate=0.05,\n",
                "    depth=6,\n",
                "    random_state=42,\n",
                "    verbose=0,\n",
                "    allow_writing_files=False\n",
                ")\n",
                "\n",
                "# Create pipelines for individual models\n",
                "pipe_xgb = Pipeline([('preprocessor', preprocessor), ('model', xgb_clf)])\n",
                "pipe_lgbm = Pipeline([('preprocessor', preprocessor), ('model', lgbm_clf)])\n",
                "pipe_cat = Pipeline([('preprocessor', preprocessor), ('model', cat_clf)])\n",
                "\n",
                "# Voting Ensemble\n",
                "voting_clf = VotingClassifier(\n",
                "    estimators=[\n",
                "        ('xgb', pipe_xgb),\n",
                "        ('lgbm', pipe_lgbm),\n",
                "        ('cat', pipe_cat)\n",
                "    ],\n",
                "    voting='soft'\n",
                ")\n",
                "\n",
                "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
                "\n",
                "print(\"Evaluating Ensemble...\")\n",
                "# Use a subset for quick check if needed\n",
                "# X_sample = X.sample(20000, random_state=42)\n",
                "# y_sample = y.loc[X_sample.index]\n",
                "scores = cross_val_score(voting_clf, X, y, cv=skf, scoring='roc_auc', n_jobs=-1)\n",
                "print(f\"Ensemble AUC: {scores.mean():.4f} (+/- {scores.std():.4f})\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f10c8e51",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Fit on full data\n",
                "voting_clf.fit(X, y)\n",
                "\n",
                "# Predict\n",
                "test_probabilities = voting_clf.predict_proba(X_test)[:, 1]\n",
                "submission = pd.DataFrame({\n",
                "    'id': test_df['id'],\n",
                "    'loan_paid_back': test_probabilities\n",
                "})\n",
                "submission.to_csv('data/advanced_submission.csv', index=False)\n",
                "print(\"Saved submission to data/advanced_submission.csv\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}